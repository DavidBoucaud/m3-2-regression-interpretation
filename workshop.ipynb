{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.weightstats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regressive Tennis T-Test\n",
    "\n",
    "Use a linear regression and statsmodels to run a t-test on whether Federer scores more points than his opponents in the `tennis.csv` dataset.\n",
    "\n",
    "Give a one-paragraph interpretation of the coefficient, and the meaning of the p-value. \n",
    "\n",
    "Also answer the following: should your regression include a constant term? Why or why not? How would it change the interpretation of your coefficient and p-value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\David\\Documents\\code\\Module 3\\m3-2-regression-interpretation\\data\\tennis.csv')\n",
    "df = df.dropna()\n",
    "df = df.sort_values(by='player1 total points won')\n",
    "\n",
    "y = df[['player1 total points won']]\n",
    "x = df[['player2 total points won']]\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "est = sm.OLS(y, X).fit(cov_type='HC2')\n",
    "print(est.summary())\n",
    "\n",
    "## In this instance, the coefficient denotes for each point Federrer scores, how many more points his opponent scores (on average). The p-value denotes that as a t-test, we can reject the null hypothesis that there is no difference in the means of the two variables.\n",
    "\n",
    "## The constant is essential in creating an accurate coefficient. Otherwise, it would measure the slope from a 0 intercept, which is not an expected score in professional tennis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. College admissions\n",
    "\n",
    "Using the `college.csv` dataset, answer the following:\n",
    "\n",
    "1. Is the relation between `Top10perc` and `Top25perc` best fit using a model with only one variable, or one variable and a polynomial of degree 2? Is a constant term useful? How would you select for the best of these model specifications?\n",
    "\n",
    "2. Do private schools see more admissions overall? T-test this using a linear regression. Hint: use a binary explanatory variable for `Private`. Explain your model specification choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\David\\Documents\\code\\Module 3\\m3-2-regression-interpretation\\data\\college.csv')\n",
    "df['Private'] = df.Private.replace(('Yes', 'No'), (1, 0))\n",
    "\n",
    "##1.\n",
    "df  = df.sort_values(by='Top25perc')\n",
    "y = df['Top10perc']\n",
    "x = df[['Top25perc']].copy()\n",
    "x['Top25perc_sq'] = x['Top25perc']**2\n",
    "\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "bad_model = sm.OLS(y,x).fit()\n",
    "model = sm.OLS(y, X[['Top25perc', 'const']]).fit()\n",
    "poly_model = sm.OLS(y, X).fit(cov_type='HC2')\n",
    "\n",
    "# print(bad_model.summary())\n",
    "# print(model.summary())\n",
    "# print(poly_model.summary())\n",
    "\n",
    "## On analyzing the AIC,BIC, and R-squared values, it is clear that including a polynomial feature improves the model. Without the constant, our AIC and BIC become much greater.\n",
    "\n",
    "##2.\n",
    "df = df.sort_values(by='Private')\n",
    "y = df[['Accept']]\n",
    "x = df[['Private']]\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "## In this case I had to leave out the constant, as we're working on a binary (0,1) and adding a constant would distort the trend we are observing between two variables.\n",
    "\n",
    "##What we are seeing is a coefficient of 1305.7, meaning that as we move from non-private (0) to Private (1), we see an average increase of just over 1000 acceptances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Auto prediction\n",
    "\n",
    "Using the `auto.csv` dataset, perform a simple linear regression with `mpg` as the response variable and horsepower as the predictor. Answer the following:\n",
    "\n",
    " i. Is there a relationship between the predictor and the response?\n",
    " \n",
    " ii. How strong is the relationship between the predictor and the response?\n",
    " \n",
    " iii. Is the relationship between the predictor and the response positive or negative?\n",
    "\n",
    " iv. What is the predicted mpg associated with a horsepower of 98? What are the associated 95 % confidence and prediction intervals ?\n",
    "\n",
    " v. Make a regression plot the response and the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, I need to clean this dataset\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\David\\Documents\\code\\Module 3\\m3-2-regression-interpretation\\data\\auto.csv')\n",
    "columns_ = df.columns.str.split()\n",
    "\n",
    "df = df.rename(columns={'mpg\\tcylinders\\tdisplacement\\thorsepower weight\\tacceleration\\tyear\\torigin\\tname': 1})\n",
    "df = df.drop([0])\n",
    "\n",
    "hold = pd.DataFrame()\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(0, len(columns_[0])):\n",
    "    df[1] = df[1].str.replace(\"   \", ' ')\n",
    "    df[1] = df[1].str.replace(\"  \", ' ')\n",
    "    df[1] = df[1].str.replace( '1\\t\"', ' ')\n",
    "    df[1] = df[1].str.replace( '2\\t\"', ' ')\n",
    "    df[1] = df[1].str.replace( '3\\t\"', ' ')\n",
    "    df[1] = df[1].str.replace( '?', '')\n",
    "    df = df[1].str.split(\" \", n = 1, expand = True) \n",
    "    hold[counter] = df[0]\n",
    "    df = df.drop([0], axis=1)\n",
    "\n",
    "    if counter <= 5:\n",
    "        hold[counter] = hold[counter].astype(float)\n",
    "    counter += 1\n",
    "\n",
    "df = pd.DataFrame(data=hold)\n",
    "\n",
    "df = df.rename(columns= {0: 'mpg' ,1:'cylinders',2:'displacement',3:'horsepower',4:'weight',5:'acceleration',6:'year',7:'origin',8:'name'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='horsepower')\n",
    "df = df.drop(df.tail(5).index) #There are some serious outliers that need to be dropped\n",
    "\n",
    "y = df.mpg\n",
    "x = df[['horsepower']]\n",
    "x['horsepower_sq'] = x['horsepower'] ** 2\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, X).fit(cov_type='HC2')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "## i. Is there a relationship between the predictor and the response?\n",
    "## Yes, the R-squared value of 0.688 denotes that our model matches at least some predictability\n",
    "\n",
    "## ii. How strong is the relationship between the predictor and the response?\n",
    "## It is alright, although I would not depict it as 'strong'. We can only\n",
    "\n",
    "## iii. Is the relationship between the predictor and the response positive or negative?\n",
    "## Positive (see coefficient).\n",
    "\n",
    "## iv. What is the predicted mpg associated with a horsepower of 98? What are the associated 95 % confidence and prediction intervals ?\n",
    "predictions = model.predict(X)\n",
    "print('The predicted mpg when horsepower is 98:', predictions.loc[predictions.index == 98].iloc[0])\n",
    "\n",
    "## v. Make a regression plot the response and the predictor.\n",
    "yfit = est.predict(X)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x['horsepower'], y, color='purple', alpha=0.4)\n",
    "ax.plot(x['horsepower'], yfit, color='blue', alpha=0.8, linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Auto Multiple Regression\n",
    "\n",
    "Perform a multiple linear regression with `mpg` as the response and all other variables except name in `auto` as the predictors. Comment on the output:\n",
    "\n",
    "i. Is there a relationship between the predictors and the response?\n",
    "\n",
    "ii. Which predictors appear to have a statistically significant relationship to the response?\n",
    "\n",
    "iii. What does the coefficient for the year variable suggest?\n",
    "\n",
    "iv. Comment on any problems you see with the fit. Do the residual plots suggest any unusually large outliers?\n",
    "\n",
    "v. Is there heteroscedasticity in the fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.copy()\n",
    "df_.year = df_.year.astype(int)\n",
    "\n",
    "y = df_.mpg\n",
    "x = df_.drop(['mpg', 'origin', 'name'], axis=1)\n",
    "\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, X).fit(cov_type='HC2')\n",
    "model.summary()\n",
    "\n",
    "## i. \n",
    "## For most of them, yes. The R-squared value denotes the existence of a relationship.\n",
    "\n",
    "## ii. \n",
    "## In reding the p-values, it appears that only horsepower, year and weight have statistically significant relationships with mpg.\n",
    "\n",
    "## iii. \n",
    "## This suggests that as the year increases by 1, the mpg increases by 0.7526.\n",
    "\n",
    "## iv. \n",
    "## The outliers in horsepower are a major problem which were immediately observeable in the residuals plot. I had to remove them in the last exercise since they seemed to ignore the very noticeable trend with mpg and skew the whole plot. Because the difference in values was so great, I felt it was fair to remove them.\n",
    "\n",
    "## v. \n",
    "## Yes there is. THis is indicated under the warnings as well as 'Covariance Type: HC2'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Car Seats\n",
    "\n",
    "This question should be answered using the Carseats data set\n",
    "\n",
    "1. Fit a multiple regression model to predict Sales using Price, Urban, and US.\n",
    "\n",
    "2. Provide an interpretation of each coefficient in the model. Be careful—some of the variables in the model are qualitative!\n",
    "\n",
    "3. For which of the predictors can you reject the null hypothesis H0 : βj = 0?\n",
    "\n",
    "4. On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.\n",
    "\n",
    "5. How well do the models in 1 and 4 fit the data? Explain which statistics show the difference.\n",
    "\n",
    "6. Using the model from (e), obtain 95 % confidence intervals for the coefficient(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               0          1\n",
       "const  11.811364  14.250221\n",
       "Price  -0.064605  -0.044350\n",
       "US      0.716136   1.683150"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>11.811364</td>\n      <td>14.250221</td>\n    </tr>\n    <tr>\n      <th>Price</th>\n      <td>-0.064605</td>\n      <td>-0.044350</td>\n    </tr>\n    <tr>\n      <th>US</th>\n      <td>0.716136</td>\n      <td>1.683150</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 385
    }
   ],
   "source": [
    "## 1.\n",
    "df = pd.read_csv(r'C:\\Users\\David\\Documents\\code\\Module 3\\m3-2-regression-interpretation\\data\\carseats.csv')\n",
    "\n",
    "df['Urban'] = df.Urban.replace(('Yes', 'No'), (1, 0))\n",
    "df['US'] = df.US.replace(('Yes', 'No'), (1, 0))\n",
    "\n",
    "y = df['Sales']\n",
    "x = df[['Price', 'Urban', 'US']]\n",
    "\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, X).fit(cov_type='HC2')\n",
    "# print(model.summary())\n",
    "\n",
    "## 2. \n",
    "## The negative coefficient for Price demonstrates that Sales decrease as the Price increases. The coefficient for Urban shows a slight decrease in Sales in urban spaces.\n",
    "\n",
    "## 3.\n",
    "## All except for Urban, which has a large p-value.\n",
    "\n",
    "## 4. On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.\n",
    "y_ = df['Sales']\n",
    "x_ = df[['Price', 'US']]\n",
    "\n",
    "X_ = sm.add_constant(x_)\n",
    "\n",
    "model_ = sm.OLS(y_, X_).fit(cov_type='HC2')\n",
    "model_.summary()\n",
    "## How well do the models in 1 and 4 fit the data? Explain which statistics show the difference.\n",
    "## The model fits fairly well. Although the low R-Squared value suggests that the observations are far from the model, the low standard errors suggest that the fit is farily accurate. The AIC and BIC also aren't terribly high.\n",
    "\n",
    "## Using the model from (e), obtain 95 % confidence intervals for the coefficient(s).\n",
    "model_.conf_int(alpha=0.05, cols=None)"
   ]
  }
 ]
}