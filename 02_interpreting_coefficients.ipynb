{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Coefficients\n",
    "\n",
    "Coefficients are the \"slope\" on each of the regression coefficients for **the relation between that x and the y**.\n",
    "\n",
    "Lets go back to the Boston House Price dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.741\nModel:                            OLS   Adj. R-squared:                  0.734\nMethod:                 Least Squares   F-statistic:                     108.1\nDate:                Sun, 03 Jan 2021   Prob (F-statistic):          6.72e-135\nTime:                        21:57:22   Log-Likelihood:                -1498.8\nNo. Observations:                 506   AIC:                             3026.\nDf Residuals:                     492   BIC:                             3085.\nDf Model:                          13                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         36.4595      5.103      7.144      0.000      26.432      46.487\nCRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\nZN             0.0464      0.014      3.382      0.001       0.019       0.073\nINDUS          0.0206      0.061      0.334      0.738      -0.100       0.141\nCHAS           2.6867      0.862      3.118      0.002       0.994       4.380\nNOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\nRM             3.8099      0.418      9.116      0.000       2.989       4.631\nAGE            0.0007      0.013      0.052      0.958      -0.025       0.027\nDIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\nRAD            0.3060      0.066      4.613      0.000       0.176       0.436\nTAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\nPTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\nB              0.0093      0.003      3.467      0.001       0.004       0.015\nLSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n==============================================================================\nOmnibus:                      178.041   Durbin-Watson:                   1.078\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\nSkew:                           1.521   Prob(JB):                    8.84e-171\nKurtosis:                       8.281   Cond. No.                     1.51e+04\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.51e+04. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Sun, 03 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>21:57:22</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n</tr>\n<tr>\n  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>   <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n</tr>\n<tr>\n  <th>CRIM</th>    <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n</tr>\n<tr>\n  <th>ZN</th>      <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n</tr>\n<tr>\n  <th>INDUS</th>   <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n</tr>\n<tr>\n  <th>CHAS</th>    <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n</tr>\n<tr>\n  <th>NOX</th>     <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n</tr>\n<tr>\n  <th>RM</th>      <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n</tr>\n<tr>\n  <th>AGE</th>     <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n</tr>\n<tr>\n  <th>DIS</th>     <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n</tr>\n<tr>\n  <th>RAD</th>     <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n</tr>\n<tr>\n  <th>TAX</th>     <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n</tr>\n<tr>\n  <th>PTRATIO</th> <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n</tr>\n<tr>\n  <th>B</th>       <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n</tr>\n<tr>\n  <th>LSTAT</th>   <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n</tr>\n<tr>\n  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "import statsmodels.api as sm\n",
    "\n",
    "boston = pd.DataFrame(load_boston().data,columns = load_boston().feature_names )\n",
    "y = load_boston().target\n",
    "\n",
    "X = sm.add_constant(boston)\n",
    "sm.OLS(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The quick scan\n",
    "\n",
    "Right away, we look at **P-Values** to see what we don't care about. AGE and INDUS are good candidates to throw out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.741\nModel:                            OLS   Adj. R-squared:                  0.735\nMethod:                 Least Squares   F-statistic:                     128.2\nDate:                Sun, 03 Jan 2021   Prob (F-statistic):          5.54e-137\nTime:                        22:11:31   Log-Likelihood:                -1498.9\nNo. Observations:                 506   AIC:                             3022.\nDf Residuals:                     494   BIC:                             3072.\nDf Model:                          11                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         36.3411      5.067      7.171      0.000      26.385      46.298\nCRIM          -0.1084      0.033     -3.307      0.001      -0.173      -0.044\nZN             0.0458      0.014      3.390      0.001       0.019       0.072\nCHAS           2.7187      0.854      3.183      0.002       1.040       4.397\nNOX          -17.3760      3.535     -4.915      0.000     -24.322     -10.430\nRM             3.8016      0.406      9.356      0.000       3.003       4.600\nDIS           -1.4927      0.186     -8.037      0.000      -1.858      -1.128\nRAD            0.2996      0.063      4.726      0.000       0.175       0.424\nTAX           -0.0118      0.003     -3.493      0.001      -0.018      -0.005\nPTRATIO       -0.9465      0.129     -7.334      0.000      -1.200      -0.693\nB              0.0093      0.003      3.475      0.001       0.004       0.015\nLSTAT         -0.5226      0.047    -11.019      0.000      -0.616      -0.429\n==============================================================================\nOmnibus:                      178.430   Durbin-Watson:                   1.078\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              787.785\nSkew:                           1.523   Prob(JB):                    8.60e-172\nKurtosis:                       8.300   Cond. No.                     1.47e+04\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.47e+04. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.735</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   128.2</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Sun, 03 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>5.54e-137</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>22:11:31</td>     <th>  Log-Likelihood:    </th> <td> -1498.9</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3022.</td> \n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>   494</td>      <th>  BIC:               </th> <td>   3072.</td> \n</tr>\n<tr>\n  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>   <td>   36.3411</td> <td>    5.067</td> <td>    7.171</td> <td> 0.000</td> <td>   26.385</td> <td>   46.298</td>\n</tr>\n<tr>\n  <th>CRIM</th>    <td>   -0.1084</td> <td>    0.033</td> <td>   -3.307</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.044</td>\n</tr>\n<tr>\n  <th>ZN</th>      <td>    0.0458</td> <td>    0.014</td> <td>    3.390</td> <td> 0.001</td> <td>    0.019</td> <td>    0.072</td>\n</tr>\n<tr>\n  <th>CHAS</th>    <td>    2.7187</td> <td>    0.854</td> <td>    3.183</td> <td> 0.002</td> <td>    1.040</td> <td>    4.397</td>\n</tr>\n<tr>\n  <th>NOX</th>     <td>  -17.3760</td> <td>    3.535</td> <td>   -4.915</td> <td> 0.000</td> <td>  -24.322</td> <td>  -10.430</td>\n</tr>\n<tr>\n  <th>RM</th>      <td>    3.8016</td> <td>    0.406</td> <td>    9.356</td> <td> 0.000</td> <td>    3.003</td> <td>    4.600</td>\n</tr>\n<tr>\n  <th>DIS</th>     <td>   -1.4927</td> <td>    0.186</td> <td>   -8.037</td> <td> 0.000</td> <td>   -1.858</td> <td>   -1.128</td>\n</tr>\n<tr>\n  <th>RAD</th>     <td>    0.2996</td> <td>    0.063</td> <td>    4.726</td> <td> 0.000</td> <td>    0.175</td> <td>    0.424</td>\n</tr>\n<tr>\n  <th>TAX</th>     <td>   -0.0118</td> <td>    0.003</td> <td>   -3.493</td> <td> 0.001</td> <td>   -0.018</td> <td>   -0.005</td>\n</tr>\n<tr>\n  <th>PTRATIO</th> <td>   -0.9465</td> <td>    0.129</td> <td>   -7.334</td> <td> 0.000</td> <td>   -1.200</td> <td>   -0.693</td>\n</tr>\n<tr>\n  <th>B</th>       <td>    0.0093</td> <td>    0.003</td> <td>    3.475</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n</tr>\n<tr>\n  <th>LSTAT</th>   <td>   -0.5226</td> <td>    0.047</td> <td>  -11.019</td> <td> 0.000</td> <td>   -0.616</td> <td>   -0.429</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>178.430</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 787.785</td> \n</tr>\n<tr>\n  <th>Skew:</th>          <td> 1.523</td>  <th>  Prob(JB):          </th> <td>8.60e-172</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 8.300</td>  <th>  Cond. No.          </th> <td>1.47e+04</td> \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X = X.drop(columns=['INDUS', 'AGE'])\n",
    "sm.OLS(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO NOTICE** Notice some of the coefficients have changed and some of the standard errors have gotten smaller. \n",
    "\n",
    "This is normal. \n",
    "\n",
    "We'll see why in the next section, but it has to do with **correlated features** (AKA multicollinearity). Removing useless features is good for these reasons.\n",
    "\n",
    "## 2. Interpretation\n",
    "\n",
    "To interpret coefficients, you need to understand the actual meaning of the numbers in the data.\n",
    "\n",
    "Let's get the description of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**  \n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n\n"
    }
   ],
   "source": [
    "print(load_boston().DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y-axis on any of the slopes is the **target variable**, $y$. Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n       18.9, 21.7, 20.4, 18.2])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is median house values, and is clearly **denominated in thousands of dollars**. So if we look at the number of rooms feature it has the collowing coefficient:\n",
    "\n",
    "**RM 3.8016 (S.D. 0.406)**\n",
    "\n",
    "Which would be interpreted as:\n",
    "\n",
    "*Increasing the number of rooms in a house by 1 would increase median house value by* $ \\$3801.6 \\pm \\$406$\n",
    "\n",
    "Since the slope is the ratio of increase of one unit of $x$ on the increase in $y$.\n",
    "\n",
    "Similarly for the **ZN** feature that's the ratio of large-zoned lots in the neighbourhood, we see \n",
    "\n",
    "**ZN\t0.0458\t0.014**\n",
    "\n",
    "Now how is the **ZN** feature formatted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      18.0\n1       0.0\n2       0.0\n3       0.0\n4       0.0\n       ... \n501     0.0\n502     0.0\n503     0.0\n504     0.0\n505     0.0\nName: ZN, Length: 506, dtype: float64"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X.ZN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $1\\%$ is encoded as **1.0**.\n",
    "\n",
    "Interpreting the coefficient above, we see that increasing the industrial zoning ratio by 1% would increase the value by  $\\$45 \\pm \\$1$.\n",
    "\n",
    "# Class exercise\n",
    "\n",
    "How do we interpret the Charles river \"dummy variable\" feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the coefficient is the jump going from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}